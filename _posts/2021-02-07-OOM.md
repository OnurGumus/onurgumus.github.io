---

layout: default

title: Out-of-Order Execution: An example
description : "A demonstration of how OOM causes problems"
date: 2021-02-07-00:00:00 -0000

comments: true

published: false

image: posts/2021-01-31-What-the-F/wheel.png

excerpt_separator: <!--more-->

---

# Out-of-Order Execution: An example"


Please take a look at below code and try to guess the output:

```csharp
using System;
using System.Threading;
using System.Threading.Tasks;

namespace MemoryBarriers
{
     class Program
    {
        static volatile int x, y, a, b;
        static void Main()
        {
            while (true)
            {
                var t1 = Task.Run(Test1);
                var t2 = Task.Run(Test2);
                Task.WaitAll(t1, t2);
                if (a == 0 && b == 0)
                {
                    Console.WriteLine("{0}, {1}", a, b);
                }
                x = y = a = b = 0;
            }
        }

        static void Test1()
        {
            x = 1;
           // Interlocked.MemoryBarrierProcessWide();
            a = y;
        }

        static void Test2()
        {
            y = 1;
            b = x;
        }
    }
}
```
In the above code, we have defined 4 fields x,y,a and b which are initialized to 0, don't mind the volatile now as we will see **volatile** keyword makes no difference here. Then we create 2 tasks calling Test1 and Test2 respectively and wait for both tasks to complete. Once both tasks are complete we check if a and b are still 0 and if so we print their values. Finally we reset everything back to 0 and re-run the same loop over and over again.

If you run the above code you will observe the output being many **0, 0**'s are printed. But that is rather surprising and let's see why.
In Test1 we set x to 1 and a to y and Test2 sets y to 1 and b to x and So we have four statements racing and let's see possible scenarios.

### Test1 then Test2:
```
x = 1
a = y
y = 1
b = x
```

In this scenario we assumed Test1 finished before Test2, then the final values will be

x = 1, a = 0 , y = 1 , b = 1

### Test2 then Test1:
```
y = 1 
b = x
x = 1
a = y
```
then

x = 1, a = 1, y = 1, b = 0


### Test2 between Test1:
```
x = 1
y = 1
b = x
a = y
```

x = 1, a = 1, y = 1 and b = 1

### Test1 between Test2
```
y = 1
x = 1
a = y
b = x
```


x = 1, a = 1, y = 1 and b = 1

### Test1 interleaving Test2

```
x = 1
y = 1
a = y
b = x
```
x = 1, a = 1, y = 1 and b = 1

### Test2 interleaving Test1
```
y = 1
x = 1
b = x
a = y
```

x = 1, a = 1, y = 1 and b = 1


I think we have covered all possible scenarios yet which ever race condition scenario occurs, it looks that it is impossible to have a and b
both simultanously zero once both tasks are completed, yet mircally our if condition triggers. How is that so?

## Explanation

The answer lies within Out Of Order Execution. Let's have a look at disassembly codes for Test1 and Test2. And if you are not familiar with x86
assembly, don't worry, it is actually very simple.

```
MemoryBarriers.Program.Test1()
    #function prolog ommitted
    L0015: mov dword ptr [rax+8], 1  # upload 1 to memory location of 'x'
    L001c: mov edx, [rax+0xc]        # download from memory location of 'y' to edx
    L001f: mov [rax+0x10], edx.      # upload from edx to memory location of 'a'
    L0022: add rsp, 0x28.           
    L0026: ret

MemoryBarriers.Program.Test2()
    #function prolog
    L0015: mov dword ptr [rax+0xc], 1 # upload 1 to memory location of 'y'
    L001c: mov edx, [rax+8].          # download from memory location of 'x' to edx
    L001f: mov [rax+0x14], edx.       # upload from edx to memory location of 'b'
    L0022: add rsp, 0x28
    L0026: ret
```

I have described precisouly what's going on on the comments next to each instruction. Please note that I have chosen to use "upload" and "download" words
instead of the conventional move terminology. For the unfamiliar ones, in order to read a value and assign it to another memory location we must read it
to the CPU registers, in this case **edx** being used for that purpose. However CPU operations are so fast, that memory access appears to be really slow compared to what we do in CPU. And that's precisly why I have used the words "upload" and "download" since today, reading and writing to memory is almost as if we 
are uploading to a remote web service. It is really that slow comparatively.

Let's these latency numbers game for 2020

```
L1 cache reference: 1 ns
L2 cache reference: 4 ns
Branch mispredict: 3 ns
Mutex lock/unlock: 17 ns
Main memory reference: 100 ns
Compress 1K bytes with Zippy: 2000 ns
Send 2K bytes over commodity network: 44 ns
Read 1 MB sequentially from memory: 3000 ns
Round trip within same datacenter: 500,000 ns
Disk seek: 2,000,000 ns
Read 1 MB sequentially from disk: 825,000 ns
Read 1 MB sequentially from SSD: 49000 ns
```
[source](https://colin-scott.github.io/personal_website/research/interactive_latency.html)

So accessing to the main memory is 100 times slower than accessing something in CPU cache. And as a developer let's say if you have independent upload
download operations to some web service. How would you design such calls? You would parallelize them! And that's precisely what our CPU does. Our beloved CPU
is smart enough to figure out that these upload and download operations do not affect each other **per thread** and in order to save from time it parallelizes them meaning the execution order of these instructions can be changed depending on which one will finish first. Hence we have **out-of-order** execution. 

However we know that our code our code is not as working as we wanted. Because the assumption our CPU made was wrong. It was only made per thread basis. Unfortuantely the CPU cannot take multiple threads into consideration when deciding instruction independence and for such cases we have to help it manually.
We will see that briefly.

## Why volatile does not help

## Memory barriers to the help
